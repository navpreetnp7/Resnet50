{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "ih33UIlR5Kjz",
    "outputId": "307059cc-ea3d-4f67-aec4-34dc531825a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "warning [drive/My Drive/32tiny-imagenet-200.zip]:  76 extra bytes at beginning or within zipfile\n",
      "  (attempting to process anyway)\n",
      "error [drive/My Drive/32tiny-imagenet-200.zip]:  reported length of central directory is\n",
      "  -76 bytes too long (Atari STZip zipfile?  J.H.Holm ZIPSPLIT 1.1\n",
      "  zipfile?).  Compensating...\n",
      "error:  expected central file header signature not found (file #120610).\n",
      "  (please check that you have transferred or created the zipfile in the\n",
      "  appropriate BINARY mode and that you have compiled UnZip properly)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip -qq \"drive/My Drive/32tiny-imagenet-200.zip\"\n",
    "\n",
    "!unzip -qq \"drive/My Drive/tiny-imagenet-200.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y6_Eh3tped8A",
    "outputId": "ea9c935a-0f13-4d59-e138-fc6dfaf04471"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    Convolution2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    "    \n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ok2jWanf8TMs"
   },
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-O4oz-IGPSg"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def neck(nip,nop,stride):\n",
    "    def unit(x):\n",
    "        nBottleneckPlane = int(nop / 4)\n",
    "        nbp = nBottleneckPlane\n",
    "\n",
    "        if nip==nop:\n",
    "            ident = x\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nbp,1,1,\n",
    "            subsample=(stride,stride))(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nbp,3,3,border_mode='same')(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nop,1,1)(x)\n",
    "\n",
    "            out = add([ident, x])\n",
    "        else:\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            ident = x\n",
    "\n",
    "            x = Convolution2D(nbp,1,1,\n",
    "            subsample=(stride,stride))(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nbp,3,3,border_mode='same')(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nop,1,1)(x)\n",
    "\n",
    "            ident = Convolution2D(nop,1,1,\n",
    "            subsample=(stride,stride))(ident)\n",
    "\n",
    "            out = add([ident, x])\n",
    "\n",
    "        return out\n",
    "    return unit\n",
    "\n",
    "def cake(nip,nop,layers,std):\n",
    "    def unit(x):\n",
    "        for i in range(layers):\n",
    "            if i==0:\n",
    "                x = neck(nip,nop,std)(x)\n",
    "            else:\n",
    "                x = neck(nop,nop,1)(x)\n",
    "        return x\n",
    "    return unit\n",
    "\n",
    "inp = Input(shape=(32,32,3))\n",
    "i = inp\n",
    "\n",
    "i = Convolution2D(16,3,3,border_mode='same')(i)\n",
    "\n",
    "i = cake(16,32,3,1)(i) #32x32\n",
    "i = cake(32,64,3,2)(i) #16x16\n",
    "i = cake(64,128,3,2)(i) #8x8\n",
    "\n",
    "i = BatchNormalization(axis=-1)(i)\n",
    "i = relu(i)\n",
    "\n",
    "i = AveragePooling2D(pool_size=(8,8),border_mode='valid')(i) #1x1\n",
    "\n",
    "i = Conv2D(200,1)(i)\n",
    "#i = Flatten()(i) # 128\n",
    "i = GlobalAveragePooling2D()(i)\n",
    "\n",
    "#i = Dense(10)(i)\n",
    "i = Activation('softmax')(i)\n",
    "\n",
    "model = Model(input=inp,output=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tGxIM-zf1_1"
   },
   "outputs": [],
   "source": [
    "filepath=\"./drive/My Drive/ChkPoint/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "-BofS-iDqDSa",
    "outputId": "d9a13465-9e51-41c2-bc81-0c1f0be3be9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200 classes\n",
      "loading training images...\n",
      "finished loading training images\n",
      "loading test images...\n",
      "finished loading test images 10000\n",
      "X_train shape: (100000, 32, 3, 32)\n",
      "100000 train samples\n",
      "X_test shape: (10000, 32, 3, 32)\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#LOAD IMAGES\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "#Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.utils.visualize_util import plot\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def get_annotations_map():\n",
    "  \n",
    "  valAnnotationsPath = './32tiny-imagenet-200/tiny-imagenet-200/val/val_annotations.txt'\n",
    "  valAnnotationsFile = open(valAnnotationsPath, 'r')\n",
    "  valAnnotationsContents = valAnnotationsFile.read()\n",
    "  valAnnotations = {}\n",
    "  for line in valAnnotationsContents.splitlines():\n",
    "    pieces = line.strip().split()\n",
    "    valAnnotations[pieces[0]] = pieces[1]\n",
    "  return valAnnotations\n",
    "\n",
    "def load_images(path,num_classes):\n",
    "    #Load images\n",
    "    \n",
    "    print('Loading ' + str(num_classes) + ' classes')\n",
    "\n",
    "    X_train=np.zeros([num_classes*500,3,32,32],dtype='uint8')\n",
    "    y_train=np.zeros([num_classes*500], dtype='uint8')\n",
    "    trainPath=path+'/train'\n",
    "\n",
    "    print('loading training images...');\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    annotations={}\n",
    "    for sChild in os.listdir(trainPath):\n",
    "        sChildPath = os.path.join(os.path.join(trainPath,sChild),'images')\n",
    "        annotations[sChild]=j\n",
    "        for c in os.listdir(sChildPath):\n",
    "            X=np.array(Image.open(os.path.join(sChildPath,c)))\n",
    "            if len(np.shape(X))==2:\n",
    "                X_train[i]=np.array([X,X,X])\n",
    "            else:\n",
    "                X_train[i]=np.transpose(X,(2,0,1))\n",
    "            y_train[i]=j\n",
    "            i+=1\n",
    "        j+=1\n",
    "        if (j >= num_classes):\n",
    "            break\n",
    "\n",
    "    print('finished loading training images')\n",
    "\n",
    "    val_annotations_map = get_annotations_map()\n",
    "\n",
    "    X_test = np.zeros([num_classes*50,3,32,32],dtype='uint8')\n",
    "    y_test = np.zeros([num_classes*50], dtype='uint8')\n",
    "\n",
    "\n",
    "    print('loading test images...')\n",
    "\n",
    "    i = 0\n",
    "    testPath=path+'/val/images'\n",
    "    for sChild in os.listdir(testPath):\n",
    "        if val_annotations_map[sChild] in annotations.keys():\n",
    "            sChildPath = os.path.join(testPath, sChild)\n",
    "            X=np.array(Image.open(sChildPath))\n",
    "            if len(np.shape(X))==2:\n",
    "                X_test[i]=np.array([X,X,X])\n",
    "            else:\n",
    "                X_test[i]=np.transpose(X,(2,0,1))\n",
    "            y_test[i]=annotations[val_annotations_map[sChild]]\n",
    "            i+=1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    print('finished loading test images ',end=\"\")\n",
    "    print(i)\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "loss_functions = ['categorical_crossentropy','squared_hinge','hinge']\n",
    "num_classes = 200\n",
    "batch_size = 128\n",
    "nb_epoch = 30\n",
    "\n",
    "#Load images\n",
    "path='./32tiny-imagenet-200/tiny-imagenet-200/'\n",
    "X_train,y_train,X_test,y_test=load_images(path,num_classes)\n",
    "\n",
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print('X_test shape:', X_test.shape)\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "num_samples=len(X_train)\n",
    "\n",
    "# input image dimensions\n",
    "num_channels , img_rows, img_cols = X_train.shape[1], X_train.shape[2], X_train.shape[3]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "z0urKXbBngXR",
    "outputId": "549a3a32-6190-4d56-f4a6-94c0e817a9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3488
    },
    "colab_type": "code",
    "id": "LfOoim56k0cn",
    "outputId": "781aa875-30e6-40bf-b389-1fa6502ee5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=781, validation_data=(array([[[..., epochs=50, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 4.7636 - acc: 0.0509 - val_loss: 4.9024 - val_acc: 0.0531\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.05310, saving model to ./drive/My Drive/ChkPoint/epochs:001-val_acc:0.053.hdf5\n",
      "Epoch 2/50\n",
      "781/781 [==============================] - 83s 106ms/step - loss: 4.3226 - acc: 0.0961 - val_loss: 4.4098 - val_acc: 0.0846\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.05310 to 0.08460, saving model to ./drive/My Drive/ChkPoint/epochs:002-val_acc:0.085.hdf5\n",
      "Epoch 3/50\n",
      "781/781 [==============================] - 85s 108ms/step - loss: 4.0978 - acc: 0.1251 - val_loss: 4.2030 - val_acc: 0.1077\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.08460 to 0.10770, saving model to ./drive/My Drive/ChkPoint/epochs:003-val_acc:0.108.hdf5\n",
      "Epoch 4/50\n",
      "781/781 [==============================] - 85s 109ms/step - loss: 3.9168 - acc: 0.1504 - val_loss: 3.9760 - val_acc: 0.1410\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.10770 to 0.14100, saving model to ./drive/My Drive/ChkPoint/epochs:004-val_acc:0.141.hdf5\n",
      "Epoch 5/50\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 3.7843 - acc: 0.1708 - val_loss: 3.8768 - val_acc: 0.1512\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.14100 to 0.15120, saving model to ./drive/My Drive/ChkPoint/epochs:005-val_acc:0.151.hdf5\n",
      "Epoch 6/50\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 3.6803 - acc: 0.1848 - val_loss: 3.7387 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.15120 to 0.17780, saving model to ./drive/My Drive/ChkPoint/epochs:006-val_acc:0.178.hdf5\n",
      "Epoch 7/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 3.5865 - acc: 0.2003 - val_loss: 3.6365 - val_acc: 0.1908\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.17780 to 0.19080, saving model to ./drive/My Drive/ChkPoint/epochs:007-val_acc:0.191.hdf5\n",
      "Epoch 8/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 3.5080 - acc: 0.2145 - val_loss: 3.7580 - val_acc: 0.1819\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.19080\n",
      "Epoch 9/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 3.4510 - acc: 0.2230 - val_loss: 3.5121 - val_acc: 0.2133\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.19080 to 0.21330, saving model to ./drive/My Drive/ChkPoint/epochs:009-val_acc:0.213.hdf5\n",
      "Epoch 10/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 3.3929 - acc: 0.2348 - val_loss: 3.4972 - val_acc: 0.2142\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.21330 to 0.21420, saving model to ./drive/My Drive/ChkPoint/epochs:010-val_acc:0.214.hdf5\n",
      "Epoch 11/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 3.3394 - acc: 0.2433 - val_loss: 3.6101 - val_acc: 0.2140\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.21420\n",
      "Epoch 12/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 3.2965 - acc: 0.2515 - val_loss: 3.6839 - val_acc: 0.2020\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.21420\n",
      "Epoch 13/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 3.2534 - acc: 0.2572 - val_loss: 3.4388 - val_acc: 0.2335\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.21420 to 0.23350, saving model to ./drive/My Drive/ChkPoint/epochs:013-val_acc:0.234.hdf5\n",
      "Epoch 14/50\n",
      "781/781 [==============================] - 88s 112ms/step - loss: 3.2168 - acc: 0.2653 - val_loss: 3.3828 - val_acc: 0.2366\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.23350 to 0.23660, saving model to ./drive/My Drive/ChkPoint/epochs:014-val_acc:0.237.hdf5\n",
      "Epoch 15/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 3.1855 - acc: 0.2715 - val_loss: 3.3012 - val_acc: 0.2541\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.23660 to 0.25410, saving model to ./drive/My Drive/ChkPoint/epochs:015-val_acc:0.254.hdf5\n",
      "Epoch 16/50\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 3.1524 - acc: 0.2781 - val_loss: 3.4151 - val_acc: 0.2376\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.25410\n",
      "Epoch 17/50\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 3.1241 - acc: 0.2826 - val_loss: 3.2797 - val_acc: 0.2582\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.25410 to 0.25820, saving model to ./drive/My Drive/ChkPoint/epochs:017-val_acc:0.258.hdf5\n",
      "Epoch 18/50\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 3.0986 - acc: 0.2878 - val_loss: 3.3202 - val_acc: 0.2568\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.25820\n",
      "Epoch 19/50\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 3.0696 - acc: 0.2922 - val_loss: 3.1505 - val_acc: 0.2795\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.25820 to 0.27950, saving model to ./drive/My Drive/ChkPoint/epochs:019-val_acc:0.280.hdf5\n",
      "Epoch 20/50\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 3.0435 - acc: 0.2984 - val_loss: 3.2803 - val_acc: 0.2571\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.27950\n",
      "Epoch 21/50\n",
      "781/781 [==============================] - 94s 121ms/step - loss: 3.0278 - acc: 0.3012 - val_loss: 3.2173 - val_acc: 0.2709\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.27950\n",
      "Epoch 22/50\n",
      "781/781 [==============================] - 95s 122ms/step - loss: 3.0038 - acc: 0.3056 - val_loss: 3.2201 - val_acc: 0.2729\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.27950\n",
      "Epoch 23/50\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 2.9780 - acc: 0.3106 - val_loss: 3.1698 - val_acc: 0.2784\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.27950\n",
      "Epoch 24/50\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 2.9633 - acc: 0.3112 - val_loss: 3.2752 - val_acc: 0.2671\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.27950\n",
      "Epoch 25/50\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 2.9451 - acc: 0.3184 - val_loss: 3.1796 - val_acc: 0.2849\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.27950 to 0.28490, saving model to ./drive/My Drive/ChkPoint/epochs:025-val_acc:0.285.hdf5\n",
      "Epoch 26/50\n",
      "781/781 [==============================] - 92s 117ms/step - loss: 2.9363 - acc: 0.3176 - val_loss: 3.1778 - val_acc: 0.2765\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.28490\n",
      "Epoch 27/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.9104 - acc: 0.3229 - val_loss: 3.2027 - val_acc: 0.2774\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.28490\n",
      "Epoch 28/50\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 2.8999 - acc: 0.3246 - val_loss: 3.1949 - val_acc: 0.2789\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.28490\n",
      "Epoch 29/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.8818 - acc: 0.3294 - val_loss: 3.0926 - val_acc: 0.2944\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.28490 to 0.29440, saving model to ./drive/My Drive/ChkPoint/epochs:029-val_acc:0.294.hdf5\n",
      "Epoch 30/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.8691 - acc: 0.3318 - val_loss: 3.1501 - val_acc: 0.2817\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.29440\n",
      "Epoch 31/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.8507 - acc: 0.3324 - val_loss: 3.0880 - val_acc: 0.2955\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.29440 to 0.29550, saving model to ./drive/My Drive/ChkPoint/epochs:031-val_acc:0.295.hdf5\n",
      "Epoch 32/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 2.8401 - acc: 0.3361 - val_loss: 3.1221 - val_acc: 0.2922\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.29550\n",
      "Epoch 33/50\n",
      "781/781 [==============================] - 88s 112ms/step - loss: 2.8258 - acc: 0.3388 - val_loss: 3.0956 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.29550\n",
      "Epoch 34/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.8165 - acc: 0.3419 - val_loss: 3.0227 - val_acc: 0.3090\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.29550 to 0.30900, saving model to ./drive/My Drive/ChkPoint/epochs:034-val_acc:0.309.hdf5\n",
      "Epoch 35/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.8019 - acc: 0.3431 - val_loss: 3.1788 - val_acc: 0.2824\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.30900\n",
      "Epoch 36/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7892 - acc: 0.3459 - val_loss: 3.2047 - val_acc: 0.2868\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.30900\n",
      "Epoch 37/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7824 - acc: 0.3482 - val_loss: 3.1230 - val_acc: 0.2900\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.30900\n",
      "Epoch 38/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7655 - acc: 0.3500 - val_loss: 3.1299 - val_acc: 0.2902\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.30900\n",
      "Epoch 39/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7609 - acc: 0.3519 - val_loss: 3.0331 - val_acc: 0.3058\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.30900\n",
      "Epoch 40/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 2.7395 - acc: 0.3530 - val_loss: 3.0462 - val_acc: 0.3093\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.30900 to 0.30930, saving model to ./drive/My Drive/ChkPoint/epochs:040-val_acc:0.309.hdf5\n",
      "Epoch 41/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7406 - acc: 0.3570 - val_loss: 3.0866 - val_acc: 0.3000\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.30930\n",
      "Epoch 42/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7213 - acc: 0.3593 - val_loss: 3.1503 - val_acc: 0.2974\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.30930\n",
      "Epoch 43/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7153 - acc: 0.3604 - val_loss: 3.0148 - val_acc: 0.3148\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.30930 to 0.31480, saving model to ./drive/My Drive/ChkPoint/epochs:043-val_acc:0.315.hdf5\n",
      "Epoch 44/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.7140 - acc: 0.3607 - val_loss: 3.0658 - val_acc: 0.2985\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.31480\n",
      "Epoch 45/50\n",
      "781/781 [==============================] - 96s 123ms/step - loss: 2.6969 - acc: 0.3628 - val_loss: 3.1356 - val_acc: 0.2961\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.31480\n",
      "Epoch 46/50\n",
      "781/781 [==============================] - 86s 111ms/step - loss: 2.6897 - acc: 0.3651 - val_loss: 3.0709 - val_acc: 0.3085\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.31480\n",
      "Epoch 47/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.6761 - acc: 0.3688 - val_loss: 3.0232 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.31480\n",
      "Epoch 48/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.6716 - acc: 0.3693 - val_loss: 3.0527 - val_acc: 0.3047\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.31480\n",
      "Epoch 49/50\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 2.6600 - acc: 0.3721 - val_loss: 3.0516 - val_acc: 0.3110\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.31480\n",
      "Epoch 50/50\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 2.6501 - acc: 0.3736 - val_loss: 3.0591 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.31480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda8034d710>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ImgAug and start training\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
    "\tsamplewise_center=False,  # set each sample mean to 0\n",
    "\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "\tsamplewise_std_normalization=False,  # divide each input by its std\n",
    "\tzca_whitening=False,  # apply ZCA whitening\n",
    "\trotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "\twidth_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "\theight_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "\thorizontal_flip=True,  # randomly flip images\n",
    "\tvertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "\t\t\t\t\tsteps_per_epoch=X_train.shape[0] // batch_size,\n",
    "\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\tepochs=50, verbose=1, max_q_size=100,\n",
    "\t\t\t\t\tcallbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AcN4byEIl6jB"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def neck(nip,nop,stride):\n",
    "    def unit(x):\n",
    "        nBottleneckPlane = int(nop / 4)\n",
    "        nbp = nBottleneckPlane\n",
    "\n",
    "        if nip==nop:\n",
    "            ident = x\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nbp,1,1,\n",
    "            subsample=(stride,stride))(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nbp,3,3,border_mode='same')(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nop,1,1)(x)\n",
    "\n",
    "            out = add([ident, x])\n",
    "        else:\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            ident = x\n",
    "\n",
    "            x = Convolution2D(nbp,1,1,\n",
    "            subsample=(stride,stride))(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nbp,3,3,border_mode='same')(x)\n",
    "\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            x = relu(x)\n",
    "            x = Convolution2D(nop,1,1)(x)\n",
    "\n",
    "            ident = Convolution2D(nop,1,1,\n",
    "            subsample=(stride,stride))(ident)\n",
    "\n",
    "            out = add([ident, x])\n",
    "\n",
    "        return out\n",
    "    return unit\n",
    "\n",
    "def cake(nip,nop,layers,std):\n",
    "    def unit(x):\n",
    "        for i in range(layers):\n",
    "            if i==0:\n",
    "                x = neck(nip,nop,std)(x)\n",
    "            else:\n",
    "                x = neck(nop,nop,1)(x)\n",
    "        return x\n",
    "    return unit\n",
    "\n",
    "inp = Input(shape=(64,64,3))\n",
    "i = inp\n",
    "\n",
    "i = Convolution2D(16,3,3,border_mode='same')(i)\n",
    "\n",
    "i = cake(16,32,3,1)(i) #32x32\n",
    "i = cake(32,64,3,2)(i) #16x16\n",
    "i = cake(64,128,3,2)(i) #8x8\n",
    "\n",
    "i = BatchNormalization(axis=-1)(i)\n",
    "i = relu(i)\n",
    "\n",
    "i = AveragePooling2D(pool_size=(8,8),border_mode='valid')(i) #1x1\n",
    "\n",
    "i = Conv2D(200,1)(i)\n",
    "#i = Flatten()(i) # 128\n",
    "i = GlobalAveragePooling2D()(i)\n",
    "\n",
    "#i = Dense(10)(i)\n",
    "i = Activation('softmax')(i)\n",
    "\n",
    "model = Model(input=inp,output=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UCRbusLI_jd"
   },
   "outputs": [],
   "source": [
    "model.load_weights('drive/My Drive/ChkPoint/epochs:043-val_acc:0.315.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qy48D9hlJH1-"
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "OYzy6d3pJhg9",
    "outputId": "d7a26dd4-bf12-450c-b1e7-b4bf5beddd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200 classes\n",
      "loading training images...\n",
      "finished loading training images\n",
      "loading test images...\n",
      "finished loading test images 10000\n",
      "X_train shape: (100000, 64, 3, 64)\n",
      "100000 train samples\n",
      "X_test shape: (10000, 64, 3, 64)\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#LOAD IMAGES\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "#Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.utils.visualize_util import plot\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_annotations_map():\n",
    "  \n",
    "  valAnnotationsPath = './32tiny-imagenet-200/tiny-imagenet-200/val/val_annotations.txt'\n",
    "  valAnnotationsFile = open(valAnnotationsPath, 'r')\n",
    "  valAnnotationsContents = valAnnotationsFile.read()\n",
    "  valAnnotations = {}\n",
    "  for line in valAnnotationsContents.splitlines():\n",
    "    pieces = line.strip().split()\n",
    "    valAnnotations[pieces[0]] = pieces[1]\n",
    "  return valAnnotations\n",
    "\n",
    "def load_images(path,num_classes):\n",
    "    #Load images\n",
    "    \n",
    "    print('Loading ' + str(num_classes) + ' classes')\n",
    "\n",
    "    X_train=np.zeros([num_classes*500,3,64,64],dtype='uint8')\n",
    "    y_train=np.zeros([num_classes*500], dtype='uint8')\n",
    "    trainPath=path+'/train'\n",
    "\n",
    "    print('loading training images...');\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    annotations={}\n",
    "    for sChild in os.listdir(trainPath):\n",
    "        sChildPath = os.path.join(os.path.join(trainPath,sChild),'images')\n",
    "        annotations[sChild]=j\n",
    "        for c in os.listdir(sChildPath):\n",
    "            X=np.array(Image.open(os.path.join(sChildPath,c)))\n",
    "            if len(np.shape(X))==2:\n",
    "                X_train[i]=np.array([X,X,X])\n",
    "            else:\n",
    "                X_train[i]=np.transpose(X,(2,0,1))\n",
    "            y_train[i]=j\n",
    "            i+=1\n",
    "        j+=1\n",
    "        if (j >= num_classes):\n",
    "            break\n",
    "\n",
    "    print('finished loading training images')\n",
    "\n",
    "    val_annotations_map = get_annotations_map()\n",
    "\n",
    "    X_test = np.zeros([num_classes*50,3,64,64],dtype='uint8')\n",
    "    y_test = np.zeros([num_classes*50], dtype='uint8')\n",
    "\n",
    "\n",
    "    print('loading test images...')\n",
    "\n",
    "    i = 0\n",
    "    testPath=path+'/val/images'\n",
    "    for sChild in os.listdir(testPath):\n",
    "        if val_annotations_map[sChild] in annotations.keys():\n",
    "            sChildPath = os.path.join(testPath, sChild)\n",
    "            X=np.array(Image.open(sChildPath))\n",
    "            if len(np.shape(X))==2:\n",
    "                X_test[i]=np.array([X,X,X])\n",
    "            else:\n",
    "                X_test[i]=np.transpose(X,(2,0,1))\n",
    "            y_test[i]=annotations[val_annotations_map[sChild]]\n",
    "            i+=1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    print('finished loading test images ',end=\"\")\n",
    "    print(i)\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "loss_functions = ['categorical_crossentropy','squared_hinge','hinge']\n",
    "num_classes = 200\n",
    "batch_size = 128\n",
    "nb_epoch = 30\n",
    "\n",
    "#Load images\n",
    "path='./tiny-imagenet-200/'\n",
    "X_train,y_train,X_test,y_test=load_images(path,num_classes)\n",
    "\n",
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print('X_test shape:', X_test.shape)\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "num_samples=len(X_train)\n",
    "\n",
    "# input image dimensions\n",
    "num_channels , img_rows, img_cols = X_train.shape[1], X_train.shape[2], X_train.shape[3]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "n28GQiDbJ7yL",
    "outputId": "64e89041-869b-4f27-8aff-382fcac62786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64, 64, 3)\n",
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3539
    },
    "colab_type": "code",
    "id": "7w8T1c8FKNQw",
    "outputId": "4142c614-6925-45ea-da51-332038beb79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=781, validation_data=(array([[[..., epochs=50, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "781/781 [==============================] - 256s 327ms/step - loss: 2.7614 - acc: 0.3549 - val_loss: 3.0157 - val_acc: 0.3169\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.31690, saving model to ./drive/My Drive/ChkPoint/epochs:001-val_acc:0.317.hdf5\n",
      "Epoch 2/50\n",
      "781/781 [==============================] - 243s 312ms/step - loss: 2.6483 - acc: 0.3740 - val_loss: 2.8588 - val_acc: 0.3377\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.31690 to 0.33770, saving model to ./drive/My Drive/ChkPoint/epochs:002-val_acc:0.338.hdf5\n",
      "Epoch 3/50\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 2.6028 - acc: 0.3830 - val_loss: 2.9439 - val_acc: 0.3322\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.33770\n",
      "Epoch 4/50\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 2.5622 - acc: 0.3905 - val_loss: 3.0117 - val_acc: 0.3231\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.33770\n",
      "Epoch 5/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.5418 - acc: 0.3946 - val_loss: 2.8753 - val_acc: 0.3376\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.33770\n",
      "Epoch 6/50\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 2.5226 - acc: 0.3977 - val_loss: 2.8178 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.33770 to 0.35570, saving model to ./drive/My Drive/ChkPoint/epochs:006-val_acc:0.356.hdf5\n",
      "Epoch 7/50\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 2.5003 - acc: 0.4024 - val_loss: 2.8595 - val_acc: 0.3403\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.35570\n",
      "Epoch 8/50\n",
      "781/781 [==============================] - 243s 312ms/step - loss: 2.4819 - acc: 0.4044 - val_loss: 2.9292 - val_acc: 0.3349\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.35570\n",
      "Epoch 9/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.4670 - acc: 0.4079 - val_loss: 2.8796 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.35570\n",
      "Epoch 10/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.4503 - acc: 0.4112 - val_loss: 2.7544 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.35570 to 0.36270, saving model to ./drive/My Drive/ChkPoint/epochs:010-val_acc:0.363.hdf5\n",
      "Epoch 11/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.4371 - acc: 0.4148 - val_loss: 2.7727 - val_acc: 0.3525\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.36270\n",
      "Epoch 12/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.4199 - acc: 0.4172 - val_loss: 2.8084 - val_acc: 0.3520\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.36270\n",
      "Epoch 13/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.4082 - acc: 0.4209 - val_loss: 2.8056 - val_acc: 0.3565\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.36270\n",
      "Epoch 14/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3989 - acc: 0.4223 - val_loss: 2.7669 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.36270 to 0.36380, saving model to ./drive/My Drive/ChkPoint/epochs:014-val_acc:0.364.hdf5\n",
      "Epoch 15/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3834 - acc: 0.4248 - val_loss: 2.7230 - val_acc: 0.3737\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.36380 to 0.37370, saving model to ./drive/My Drive/ChkPoint/epochs:015-val_acc:0.374.hdf5\n",
      "Epoch 16/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3741 - acc: 0.4264 - val_loss: 2.6809 - val_acc: 0.3763\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.37370 to 0.37630, saving model to ./drive/My Drive/ChkPoint/epochs:016-val_acc:0.376.hdf5\n",
      "Epoch 17/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3607 - acc: 0.4300 - val_loss: 2.8868 - val_acc: 0.3414\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.37630\n",
      "Epoch 18/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3584 - acc: 0.4301 - val_loss: 2.7164 - val_acc: 0.3692\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.37630\n",
      "Epoch 19/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3477 - acc: 0.4326 - val_loss: 2.7941 - val_acc: 0.3584\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.37630\n",
      "Epoch 20/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3346 - acc: 0.4354 - val_loss: 3.0069 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.37630\n",
      "Epoch 21/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.3249 - acc: 0.4370 - val_loss: 2.7434 - val_acc: 0.3738\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.37630\n",
      "Epoch 22/50\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 2.3158 - acc: 0.4393 - val_loss: 2.7619 - val_acc: 0.3630\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.37630\n",
      "Epoch 23/50\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 2.3050 - acc: 0.4417 - val_loss: 2.7261 - val_acc: 0.3680\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.37630\n",
      "Epoch 24/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.3018 - acc: 0.4414 - val_loss: 2.5922 - val_acc: 0.3921\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.37630 to 0.39210, saving model to ./drive/My Drive/ChkPoint/epochs:024-val_acc:0.392.hdf5\n",
      "Epoch 25/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2909 - acc: 0.4428 - val_loss: 2.8693 - val_acc: 0.3479\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.39210\n",
      "Epoch 26/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2810 - acc: 0.4468 - val_loss: 2.7959 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.39210\n",
      "Epoch 27/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2761 - acc: 0.4478 - val_loss: 2.6228 - val_acc: 0.3882\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.39210\n",
      "Epoch 28/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2646 - acc: 0.4501 - val_loss: 2.6680 - val_acc: 0.3872\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.39210\n",
      "Epoch 29/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2544 - acc: 0.4513 - val_loss: 2.7658 - val_acc: 0.3819\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.39210\n",
      "Epoch 30/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2533 - acc: 0.4531 - val_loss: 2.7565 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.39210\n",
      "Epoch 31/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2429 - acc: 0.4549 - val_loss: 2.8060 - val_acc: 0.3593\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.39210\n",
      "Epoch 32/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.2423 - acc: 0.4552 - val_loss: 2.6797 - val_acc: 0.3787\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.39210\n",
      "Epoch 33/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.2277 - acc: 0.4572 - val_loss: 2.7180 - val_acc: 0.3772\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.39210\n",
      "Epoch 34/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.2228 - acc: 0.4585 - val_loss: 2.6588 - val_acc: 0.3937\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.39210 to 0.39370, saving model to ./drive/My Drive/ChkPoint/epochs:034-val_acc:0.394.hdf5\n",
      "Epoch 35/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.2168 - acc: 0.4590 - val_loss: 2.6818 - val_acc: 0.3822\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.39370\n",
      "Epoch 36/50\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 2.2110 - acc: 0.4606 - val_loss: 2.7064 - val_acc: 0.3810\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.39370\n",
      "Epoch 37/50\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 2.2050 - acc: 0.4624 - val_loss: 2.6893 - val_acc: 0.3766\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.39370\n",
      "Epoch 38/50\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 2.2001 - acc: 0.4625 - val_loss: 2.7411 - val_acc: 0.3717\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.39370\n",
      "Epoch 39/50\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 2.1964 - acc: 0.4634 - val_loss: 2.6637 - val_acc: 0.3817\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.39370\n",
      "Epoch 40/50\n",
      "781/781 [==============================] - 242s 309ms/step - loss: 2.1873 - acc: 0.4654 - val_loss: 2.6560 - val_acc: 0.3875\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.39370\n",
      "Epoch 41/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1810 - acc: 0.4665 - val_loss: 2.6156 - val_acc: 0.4008\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.39370 to 0.40080, saving model to ./drive/My Drive/ChkPoint/epochs:041-val_acc:0.401.hdf5\n",
      "Epoch 42/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1746 - acc: 0.4690 - val_loss: 2.6199 - val_acc: 0.3972\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.40080\n",
      "Epoch 43/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1701 - acc: 0.4701 - val_loss: 2.7331 - val_acc: 0.3781\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.40080\n",
      "Epoch 44/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1635 - acc: 0.4706 - val_loss: 2.7753 - val_acc: 0.3783\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.40080\n",
      "Epoch 45/50\n",
      "781/781 [==============================] - 245s 313ms/step - loss: 2.1592 - acc: 0.4700 - val_loss: 2.5600 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.40080\n",
      "Epoch 46/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.1523 - acc: 0.4741 - val_loss: 2.5972 - val_acc: 0.3985\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.40080\n",
      "Epoch 47/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.1486 - acc: 0.4726 - val_loss: 2.4891 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.40080 to 0.41730, saving model to ./drive/My Drive/ChkPoint/epochs:047-val_acc:0.417.hdf5\n",
      "Epoch 48/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.1466 - acc: 0.4745 - val_loss: 2.6686 - val_acc: 0.3975\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.41730\n",
      "Epoch 49/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.1407 - acc: 0.4749 - val_loss: 2.6399 - val_acc: 0.3951\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.41730\n",
      "Epoch 50/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1322 - acc: 0.4783 - val_loss: 2.6944 - val_acc: 0.3891\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.41730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80b759d908>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"./drive/My Drive/ChkPoint/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ImgAug and start training\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "\tfeaturewise_center=False,  # set input mean to 0 over the dataset\n",
    "\tsamplewise_center=False,  # set each sample mean to 0\n",
    "\tfeaturewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "\tsamplewise_std_normalization=False,  # divide each input by its std\n",
    "\tzca_whitening=False,  # apply ZCA whitening\n",
    "\trotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "\twidth_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "\theight_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "\thorizontal_flip=True,  # randomly flip images\n",
    "\tvertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "\t\t\t\t\tsteps_per_epoch=X_train.shape[0] // batch_size,\n",
    "\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\tepochs=50, verbose=1, max_q_size=100,\n",
    "\t\t\t\t\tcallbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3029
    },
    "colab_type": "code",
    "id": "5wjgNZ6P8yVE",
    "outputId": "7acddae5-1f9d-479f-e231-5cd8a112b10e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=781, validation_data=(array([[[..., epochs=50, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.1298 - acc: 0.4784 - val_loss: 2.6196 - val_acc: 0.4051\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.41730\n",
      "Epoch 2/50\n",
      "781/781 [==============================] - 242s 309ms/step - loss: 2.1218 - acc: 0.4810 - val_loss: 2.5946 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.41730\n",
      "Epoch 3/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1181 - acc: 0.4770 - val_loss: 2.7100 - val_acc: 0.3814\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.41730\n",
      "Epoch 4/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1159 - acc: 0.4794 - val_loss: 2.5663 - val_acc: 0.4032\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.41730\n",
      "Epoch 5/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1086 - acc: 0.4802 - val_loss: 2.5395 - val_acc: 0.4071\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.41730\n",
      "Epoch 6/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1048 - acc: 0.4802 - val_loss: 2.6746 - val_acc: 0.3955\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.41730\n",
      "Epoch 7/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.1041 - acc: 0.4817 - val_loss: 2.5960 - val_acc: 0.4075\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.41730\n",
      "Epoch 8/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0933 - acc: 0.4833 - val_loss: 2.5677 - val_acc: 0.4114\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.41730\n",
      "Epoch 9/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0924 - acc: 0.4836 - val_loss: 2.5961 - val_acc: 0.3966\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.41730\n",
      "Epoch 10/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0833 - acc: 0.4859 - val_loss: 2.7397 - val_acc: 0.3889\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.41730\n",
      "Epoch 11/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0780 - acc: 0.4884 - val_loss: 2.6283 - val_acc: 0.3945\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.41730\n",
      "Epoch 12/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0771 - acc: 0.4897 - val_loss: 2.6746 - val_acc: 0.3949\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.41730\n",
      "Epoch 13/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0750 - acc: 0.4875 - val_loss: 2.7132 - val_acc: 0.3840\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.41730\n",
      "Epoch 14/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0701 - acc: 0.4889 - val_loss: 2.6681 - val_acc: 0.3938\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.41730\n",
      "Epoch 15/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0645 - acc: 0.4903 - val_loss: 2.5078 - val_acc: 0.4162\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.41730\n",
      "Epoch 16/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0645 - acc: 0.4922 - val_loss: 2.5547 - val_acc: 0.4082\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.41730\n",
      "Epoch 17/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0587 - acc: 0.4920 - val_loss: 2.5428 - val_acc: 0.4031\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.41730\n",
      "Epoch 18/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0529 - acc: 0.4937 - val_loss: 2.6262 - val_acc: 0.3960\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.41730\n",
      "Epoch 19/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0499 - acc: 0.4942 - val_loss: 2.4904 - val_acc: 0.4210\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.41730 to 0.42100, saving model to ./drive/My Drive/ChkPoint/epochs:019-val_acc:0.421.hdf5\n",
      "Epoch 20/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0449 - acc: 0.4940 - val_loss: 2.7068 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.42100\n",
      "Epoch 21/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0428 - acc: 0.4954 - val_loss: 2.5653 - val_acc: 0.4077\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.42100\n",
      "Epoch 22/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0476 - acc: 0.4943 - val_loss: 2.7682 - val_acc: 0.3848\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.42100\n",
      "Epoch 23/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0351 - acc: 0.4975 - val_loss: 2.6474 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.42100\n",
      "Epoch 24/50\n",
      "781/781 [==============================] - 243s 312ms/step - loss: 2.0348 - acc: 0.4971 - val_loss: 2.5129 - val_acc: 0.4138\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.42100\n",
      "Epoch 25/50\n",
      "781/781 [==============================] - 244s 313ms/step - loss: 2.0366 - acc: 0.4967 - val_loss: 2.6582 - val_acc: 0.3932\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.42100\n",
      "Epoch 26/50\n",
      "781/781 [==============================] - 245s 313ms/step - loss: 2.0253 - acc: 0.4994 - val_loss: 2.6241 - val_acc: 0.4025\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.42100\n",
      "Epoch 27/50\n",
      "781/781 [==============================] - 244s 313ms/step - loss: 2.0231 - acc: 0.4981 - val_loss: 2.5231 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.42100\n",
      "Epoch 28/50\n",
      "781/781 [==============================] - 244s 313ms/step - loss: 2.0228 - acc: 0.5004 - val_loss: 2.5186 - val_acc: 0.4203\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.42100\n",
      "Epoch 29/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0176 - acc: 0.5016 - val_loss: 2.5262 - val_acc: 0.4139\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.42100\n",
      "Epoch 30/50\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 2.0133 - acc: 0.5029 - val_loss: 2.5925 - val_acc: 0.4056\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.42100\n",
      "Epoch 31/50\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 2.0118 - acc: 0.5023 - val_loss: 2.5222 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.42100\n",
      "Epoch 32/50\n",
      "781/781 [==============================] - 244s 313ms/step - loss: 2.0104 - acc: 0.5024 - val_loss: 2.6733 - val_acc: 0.3977\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.42100\n",
      "Epoch 33/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0092 - acc: 0.5024 - val_loss: 2.5618 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.42100\n",
      "Epoch 34/50\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 2.0017 - acc: 0.5035 - val_loss: 2.6447 - val_acc: 0.3989\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.42100\n",
      "Epoch 35/50\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 1.9950 - acc: 0.5051 - val_loss: 2.5240 - val_acc: 0.4213\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.42100 to 0.42130, saving model to ./drive/My Drive/ChkPoint/epochs:035-val_acc:0.421.hdf5\n",
      "Epoch 36/50\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 1.9963 - acc: 0.5053 - val_loss: 2.6307 - val_acc: 0.4023\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.42130\n",
      "Epoch 37/50\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 1.9936 - acc: 0.5048 - val_loss: 2.6203 - val_acc: 0.4111\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.42130\n",
      "Epoch 38/50\n",
      "781/781 [==============================] - 245s 313ms/step - loss: 1.9905 - acc: 0.5050 - val_loss: 2.5937 - val_acc: 0.4154\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.42130\n",
      "Epoch 39/50\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 1.9858 - acc: 0.5057 - val_loss: 2.5080 - val_acc: 0.4209\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.42130\n",
      "Epoch 40/50\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 1.9792 - acc: 0.5086 - val_loss: 2.5548 - val_acc: 0.4125\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.42130\n",
      "Epoch 41/50\n",
      "781/781 [==============================] - 245s 313ms/step - loss: 1.9841 - acc: 0.5082 - val_loss: 2.6227 - val_acc: 0.4109\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.42130\n",
      "Epoch 42/50\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 1.9743 - acc: 0.5092 - val_loss: 2.5410 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.42130\n",
      "Epoch 43/50\n",
      "781/781 [==============================] - 246s 315ms/step - loss: 1.9752 - acc: 0.5093 - val_loss: 2.4971 - val_acc: 0.4239\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.42130 to 0.42390, saving model to ./drive/My Drive/ChkPoint/epochs:043-val_acc:0.424.hdf5\n",
      "Epoch 44/50\n",
      " 48/781 [>.............................] - ETA: 3:36 - loss: 2.0128 - acc: 0.5024"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "\t\t\t\t\tsteps_per_epoch=X_train.shape[0] // batch_size,\n",
    "\t\t\t\t\tvalidation_data=(X_test, Y_test),\n",
    "\t\t\t\t\tepochs=50, verbose=1, max_q_size=100,\n",
    "\t\t\t\t\tcallbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1byIs_zw0-G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of NewResnet10",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
